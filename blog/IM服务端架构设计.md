## IM服务端架构设计

#### 1.基于mqtt的长连接

1.感知用户在线状态：

​		~~客户端在connect回调中向"im/connect" 发送一条msg，带上自己的user_id~~ 使用EMQX的system topic中的[监听客户端上下线行为][https://www.emqx.io/docs/zh/v4.3/advanced/system-topic.html]的topic； 服务端监听这个topic 维护一个bitmap（调研bloom过滤器是否可用）代表用户是否在线，客户端离线变动由mqtt[遗嘱][https://www.emqx.com/zh/blog/use-of-mqtt-will-message]保证,即客户端的mqtt client 断连时发送一个消息 服务端监听这个消息，维护在线状态

2.topic设计，分两种情况， 一种是IM实体topic，一种是业务运营需求topic

- IM实体topic
  1. 私信topic 这种较为简单，以user_id作为划分根据，即形如“single/123123123”
  2. 群聊topic 以群聊id作为划分根据，即形如"group/567576567",需要注意的是 客户端发起建群请求之后即可sub这个群聊的topic，服务端在收到建群人的消息之后 要给建群人邀请的其他群成员的私信topic发送邀请（sub）msg（带group_id）客户端收到后可以存储，这个群聊关系由IM维护
- 业务运营topic
  1. 全局消息，客户端默认sub全局消息topic，意味着全局消息的扩散方式为读扩散（和服务端设计保持一致）
  2. tag运营消息（e.g.分组运营）各自有一部分topic 具体每个用户该订阅哪些topic由服务端下发 服务端维护（维护指通过后台人工配置，根据推荐系统构造的用户画像，用户行为如特别关注等方式）用户应该订阅的topic，举个例子 如果运营的需求是给全体女性用户推一个消息 则直接往"business/tag_female"这样的topic下发一条msg就ok ，这样就可以做到分组运营

3.全局mqtt消息原则上一律基于[QOS][https://www.emqx.com/zh/blog/introduction-to-mqtt-qos]1下发 原则上不采用QOS2，由客户端做幂等处理，个别运营消息（在线运营）可以采用QOS 0下发 减少用户打扰

#### 2.服务端存储设计

- 写扩散部分：

  - 每个user有一个作为reciver的timeline
  - timeline实现：每个写入timeline的msg有一个唯一id（last_id）last_id严格按时间递增，以这个id作为score将消息存入redis的zset。每次像timeline写入最新消息时 对于timeline中的早于7日前的消息做失效处理；此处有两点注意：
    1. 在写入timeline时 同时对消息落盘（mysql），所以现在服务端表现上只支持7日内消息漫游 实际可拓展为当月消息漫游，季度消息漫游，年度消息漫游等不同粒度（后两种需要聚合数据）
    2. timeline的消息失效处理是惰性的，即有读取或者写入操作时才会进行失效处理 所以在存储空间内可能会长期存在一些僵尸用户的timeline吞噬内存空间，后续可以设计离线任务进行主动清理僵尸用户timeline
  - 客户端每次拉取消息的时候带上一次拉到的最后一条last_id 服务端使用这个last_id作为偏移量下发这个时间点之后的消息

- 读扩散部分：

  - 全局消息 ：所有全局消息放在一个全局的timeline里 客户端拉取消息时候使用请求体里的last_id作为偏移量 按lastId排序 聚合私有timeline的消息

- 读写皆可，根据业务设计具体确定部分

  群聊消息：群聊有两种设计方案 各有侧重点 根据具体需求设计选择方案

  1. 读扩散方式：参考全局消息部分设计 但是和全局消息不同的是 服务端需要用一个redis set（待定）维护每一个用户在两次拉取消息之间的时间中有新消息的group_id 然后拉取消息时仿照全局消息设计 进行聚合

     ps:如有必要,热点的群做自适应的本地缓存：如果某个redis-key某段时间命中数过多 则启动一个1s一次的请求 将最近1s的消息同步到local cache

     - 优点：比起写扩散方式 群聊消息只存一份 减少了存储压力 节省成本 
     - 缺点：每次拉取消息时 要遍历有新消息的所有群聊拿到偏移量之后的消息再进行聚合，多了n次io操作和内存拷贝
     - 适用场景 ：类似QQ群场景 对建群数量有较大限制或者门槛，对于一个人加群的最大上限也有限制，这样保证一次拉取请求不会需要聚合巨量活跃群的消息 

  2. 写扩散方式：参考私信部分设计，群聊消息写入每个user的timeline ，用户拉取消息时直接可以拉到群聊消息不用聚合

     - 优点：比起读扩散方式，用户拉取消息的时候 可能的服务端压力、接口时延都要比读扩散更友好 因为减少了若干次IO和内存拷贝
     - 缺点：消息存储冗余 存储成本高
     - 适用场景：类似微信，飞书这种建群操作比较轻量级，没有数量上线 但是对群人数有严格限制的场景，确保消息存储的冗余空间不会特别夸张的膨胀

  3. 当然也可以模仿QQ早期的QQ群、讨论组并行的设计 对于两种群聊方式分别采取不同的存储设计





​			